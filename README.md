I wanted to create a Neural Network from scratch as I heard it's a great way to really get a grasp for the underlying mechanics in classical ML

I started off by learning a lot (!) of theory. Thankfully there's no shortage of resources online. 
As soon as I feel like I've gotten a comfortable grasp of an aspect I turn it into code

As of July 6th 2025 I have initialized parameters for forward propogation, as I feel like I've built a strong grasp for how it works

Backprop is a whole other beast...

I don't want to spend too much time on the advanced mathematics for gradient descent as I have lot's of gaps in my knowledge. 
After some more time and lessons in differential equations and linear algebra, I'll revisit the back prop

What I've learned:
- Basic knowledge of neural networks and how they work under the hood

What I wish to add:
- Learn the mathematical background of back prop properly before I commit to turning this into code.
- In the meantime: research other ML models and see if I can make those from scratch (I don't know how feasable this is)
- eventually try turning those codes into c++ or rust as these are languages I would really like to start learning this year
